{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNY4E0xnc7GBdYknb01JCv2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0EwXaQ6WmT-1"},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","import pandas as pd\n","\n","file_path = 'translated_data.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv(file_path, encoding='utf-8')\n","\n","# Remove '%' symbol and convert 'Open Rate' and 'Click Rate' to numeric\n","df['Open Rate'] = df['Open Rate'].str.rstrip('%').astype('float') / 100.0\n","df['Click Rate'] = df['Click Rate'].str.rstrip('%').astype('float') / 100.0\n","\n","# features and target variables\n","text_features_column = 'Subjectline_English'\n","categorical_features = ['Region', 'Division', 'MAP_B&B', 'Email_Type']\n","\n","# Feature Engineering\n","text_vectorizer = TfidfVectorizer(\n","    stop_words=None,\n","    sublinear_tf=True,\n","    max_features=1000\n",")\n","\n","categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","# Combine text and categorical features using ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('text', text_vectorizer, text_features_column),\n","        ('cat', categorical_transformer, categorical_features)\n","    ])\n","\n","# pipeline with preprocessing and model training for open rate\n","open_rate_pipeline = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('model', RandomForestRegressor())\n","])\n","\n","# pipeline with preprocessing and model training for click rate\n","click_rate_pipeline = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('model', RandomForestRegressor())\n","])\n","\n","# models for each target variable\n","open_rate_pipeline.fit(df.drop(['Open Rate', 'Click Rate'], axis=1), df['Open Rate'])\n","click_rate_pipeline.fit(df.drop(['Open Rate', 'Click Rate'], axis=1), df['Click Rate'])\n","\n","# top keywords for each Division, Region, Email_Type, and MAP_B&B\n","unique_divisions = df['Division'].unique()\n","unique_regions = df['Region'].unique()\n","unique_mab_bnb = df['MAP_B&B'].unique()\n","\n","for division in unique_divisions:\n","    for region in unique_regions:\n","        for mab_bnb in unique_mab_bnb:\n","            subset_df = df[(df['Division'] == division) & (df['Region'] == region) & (df['MAP_B&B'] == mab_bnb)]\n","\n","            if not subset_df.empty:\n","                # features for the subset\n","                subset_features = subset_df.drop(['Open Rate', 'Click Rate'], axis=1)\n","                text_vectorizer.fit(subset_features['Subjectline_English'])\n","\n","                # Predict for open rate\n","                open_rate_pipeline.predict(subset_features)\n","\n","                # feature importance (coefficients) for text features\n","                feature_importance_text = open_rate_pipeline.named_steps['model'].feature_importances_\n","\n","                # feature names for text features directly from the vocabulary\n","                feature_names_text = text_vectorizer.get_feature_names_out()\n","                vocabulary = text_vectorizer.vocabulary_\n","\n","                # Ensure the number of features is not greater than the available vocabulary\n","                num_features = min(len(vocabulary), 1000)\n","\n","                # Indices of the top keywords based on feature importance\n","                top_keywords_indices = feature_importance_text.argsort()[-num_features:][::-1]\n","\n","                # actual top keywords, removing numbers and non-alphabetic characters\n","                top_keywords = [word for word, idx in sorted(vocabulary.items(), key=lambda x: x[1]) if idx in top_keywords_indices and word.isalpha()]\n","\n","                # results or further analysis\n","                print(f\"For Division '{division}', Region '{region}', and MAP_B&B '{mab_bnb}':\")\n","                print(f\"Top Keywords: {', '.join(top_keywords)}\")\n","                print(\"\\n\")\n"]}]}